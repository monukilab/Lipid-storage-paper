{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPEC detection RetinaNet model training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biondi, copy, glob, matplotlib\n",
    "import numpy as np\n",
    "from tensorflow.keras import models\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "from keras_tuner.engine import tuner_utils\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image and label dataset filepaths\n",
    "training_dataset_image_dir = ''\n",
    "training_dataset_label_dir = ''\n",
    "validation_dataset_image_dir = ''\n",
    "validation_dataset_label_dir = ''\n",
    "test_dataset_image_dir = ''\n",
    "test_dataset_label_dir = ''\n",
    "# load datasets\n",
    "train_x = np.load(training_dataset_image_dir)\n",
    "train_y = (np.load(training_dataset_label_dir)>2).astype('uint8')\n",
    "validation_x = np.load(validation_dataset_image_dir)\n",
    "validation_y = (np.load(validation_dataset_label_dir)>2).astype('uint8')\n",
    "test_x = np.load(test_dataset_image_dir)\n",
    "test_y = (np.load(test_dataset_label_dir)>2).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data generators which will be passed to the keras model for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgen = biondi.dataset.TrainingGenerator(train_x, batch_size=64,labels=keras.utils.to_categorical(train_y, num_classes=2),flip=True, rotation=True, contrast=True,)\n",
    "vgen = biondi.dataset.TrainingGenerator(validation_x, batch_size=64, labels=keras.utils.to_categorical(validation_y, num_classes=2), validation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOptimizationCV(kt.BayesianOptimization):\n",
    "    def helper_fn(self, data, labels, **kwargs):\n",
    "        kf = sklearn.model_selection.KFold(n_splits=self.executions_per_trial, shuffle=True)\n",
    "        kfgen = kf.split(X=data)\n",
    "        return kf, kfgen, data, labels\n",
    "    \n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        model_checkpoint = tuner_utils.SaveBestEpoch(\n",
    "            objective=self.oracle.objective,\n",
    "            filepath=self._get_checkpoint_fname(trial.trial_id),\n",
    "        )\n",
    "        original_callbacks = kwargs.pop(\"callbacks\", [])\n",
    "\n",
    "        # Run the training process multiple times.\n",
    "        histories = []\n",
    "        kf, kfgen, data, labels = self.helper_fn(*args)\n",
    "\n",
    "        for execution in range(self.executions_per_trial):\n",
    "            copied_kwargs = copy.copy(kwargs)\n",
    "            callbacks = self._deepcopy_callbacks(original_callbacks)\n",
    "            self._configure_tensorboard_dir(callbacks, trial, execution)\n",
    "            callbacks.append(tuner_utils.TunerCallback(self, trial))\n",
    "            # Only checkpoint the best epoch across all executions.\n",
    "            callbacks.append(model_checkpoint)\n",
    "            copied_kwargs[\"callbacks\"] = callbacks\n",
    "            train_idx, test_idx = next(kfgen)\n",
    "            tgen = biondi.dataset.TrainingGenerator(data=data[train_idx],\n",
    "                                     labels=labels[train_idx],\n",
    "                                     batch_size=64,\n",
    "                                     flip=True,\n",
    "                                     rotation=True,\n",
    "                                     contrast=True,\n",
    "                                     **kwargs)\n",
    "            vgen = biondi.dataset.TrainingGenerator(data=data[test_idx],\n",
    "                                     labels=labels[test_idx],\n",
    "                                     batch_size=64,\n",
    "                                     validation=True,\n",
    "                                     **kwargs)\n",
    "            obj_value = self._build_and_fit_model(trial, x=tgen, validation_data=vgen, **copied_kwargs)\n",
    "\n",
    "            histories.append(obj_value)\n",
    "        return histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create KerasTuner tuner object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify working directory \n",
    "tuner_dir = ''\n",
    "# Specify project name\n",
    "tuner_name = ''\n",
    "tuner = BayesianOptimizationCV(kt.applications.HyperResNet(\n",
    "    input_shape=(128,128,3), \n",
    "    classes=2,), \n",
    "    objective='val_loss', \n",
    "    max_trials=20, \n",
    "    executions_per_trial=5, \n",
    "    project_name=tuner_name, \n",
    "    directory=tuner_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_x, keras.utils.to_categorical(train_y, num_classes=2), workers=14, max_queue_size=200, epochs=50, class_weight = {0:1, 1:2.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimized hyperparamters\n",
    "optmized_hp = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model parameters (determined by hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'version': 'next',\n",
    "    'conv3_depth': 8,\n",
    "    'conv4_depth': 36,\n",
    "    'pooling': 'avg',\n",
    "    'optimizer': 'rmsprop',\n",
    "    'learning_rate': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model using optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create checkpoint object to save the model after each epoch (optional).\n",
    "chckpnt_dir = ''\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=chckpnt_dir + 'model_epoch-{epoch:02d}_val_loss-{val_loss:.4f}_val_accuracy-{val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model. Depending on system resources the number of workers and the max_queue_size can be adjusted.\n",
    "# remove callbacks parameter if model checkpoints are not needed.\n",
    "trainhist = model.fit(x=tgen, validation_data=vgen, epochs=50, class_weight={0:1,1:5.9}, workers=14, max_queue_size=200, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize model training and performance across epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of model checkpoint saves\n",
    "chckpnts = sorted(glob.glob(chckpnt_dir + 'model_epoch*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract validation loss, positive predictive value, and sensitivity from model checkpoint filenames.\n",
    "plt.plot(trainhist.history['val_loss'])\n",
    "plt.plot(trainhist.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance statistics on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize image data\n",
    "norm_test_x = biondi.dataset.per_sample_tile_normalization(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model checkpoint filepath\n",
    "test_model_checkpoint = ''\n",
    "test_model = models.load_model(test_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model predictions on test dataset\n",
    "softmax_scores = test_model.predict(norm_test_x)\n",
    "predictions = np.argmax(softmax_scores, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get true/false positives/negatives (TP, FP, TN, FN) for model predictions\n",
    "TP, FP, TN, FN = biondi.statistics.binary_tpfptnfn(predictions, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate binary sensitivity, precision, & accuracy\n",
    "print(\"Sensitivity:\", TP/(TP+FN))\n",
    "print(\"Precision:\", TP/(TP+FP))\n",
    "print(\"Accuracy:\", np.sum(test_y==predictions)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate area under the receiver operating characteristic curve (AUROC)\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(test_y, softmax_scores[:,1:])\n",
    "roc_auc = sklearn.metrics.roc_auc_score(test_y, softmax_scores[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize curve\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "plt.rcParams['legend.title_fontsize'] = 12\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "g = sns.lineplot(x=fpr, y=tpr, palette=sns.color_palette('tab10'), label='ROC curve (area = %0.2f)' % roc_auc, ax=ax)\n",
    "plt.legend(loc='lower right',frameon=False)\n",
    "plt.ylabel('True positive rate (TPR)', fontweight='bold', fontsize=18)\n",
    "plt.xlabel('False positive rate (FPR)', fontweight='bold', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
